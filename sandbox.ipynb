{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_data as impt\n",
    "import numpy as np\n",
    "\n",
    "(x_dim, x_dim_cont, x_dim_bin), (data, time, label), (mask1, mask2, mask3), (data_mi) = impt.import_dataset(norm_mode = 'standard')\n",
    "\n",
    "_, num_Event, num_Category  = np.shape(mask1)  # dim of mask3: [subj, Num_Event, Num_Category]\n",
    "max_length                  = np.shape(data)[1]\n",
    "\n",
    "pred_time = [52, 3*52, 5*52] # prediction time (in months)\n",
    "eval_time = [12, 36, 60, 120] # months evaluation time (for C-index and Brier-Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparams\n",
    "burn_in_mode                = 'ON' #{'ON', 'OFF'}\n",
    "boost_mode                  = 'ON' #{'ON', 'OFF'}\n",
    "\n",
    "##### HYPER-PARAMETERS\n",
    "new_parser = {'mb_size': 32,\n",
    "\n",
    "             'iteration_burn_in': 3000,\n",
    "             'iteration': 25000,\n",
    "\n",
    "             'keep_prob': 0.6,\n",
    "             'lr_train': 1e-4,\n",
    "\n",
    "             'h_dim_RNN': 100,\n",
    "             'h_dim_FC' : 100,\n",
    "             'num_layers_RNN':2,\n",
    "             'num_layers_ATT':2,\n",
    "             'num_layers_CS' :2,\n",
    "\n",
    "             'RNN_type':'LSTM', #{'LSTM', 'GRU'}\n",
    "\n",
    "             'FC_active_fn' : tf.nn.relu,\n",
    "             'RNN_active_fn': tf.nn.tanh,\n",
    "\n",
    "            'reg_W'         : 1e-5,\n",
    "            'reg_W_out'     : 0.,\n",
    "\n",
    "             'alpha' :1.0,\n",
    "             'beta'  :0.1,\n",
    "             'gamma' :1.0\n",
    "}\n",
    "\n",
    "\n",
    "# INPUT DIMENSIONS\n",
    "input_dims                  = { 'x_dim'         : x_dim,\n",
    "                                'x_dim_cont'    : x_dim_cont,\n",
    "                                'x_dim_bin'     : x_dim_bin,\n",
    "                                'num_Event'     : num_Event,\n",
    "                                'num_Category'  : num_Category,\n",
    "                                'max_length'    : max_length }\n",
    "\n",
    "# NETWORK HYPER-PARMETERS\n",
    "network_settings            = { 'h_dim_RNN'         : new_parser['h_dim_RNN'],\n",
    "                                'h_dim_FC'          : new_parser['h_dim_FC'],\n",
    "                                'num_layers_RNN'    : new_parser['num_layers_RNN'],\n",
    "                                'num_layers_ATT'    : new_parser['num_layers_ATT'],\n",
    "                                'num_layers_CS'     : new_parser['num_layers_CS'],\n",
    "                                'RNN_type'          : new_parser['RNN_type'],\n",
    "                                'FC_active_fn'      : new_parser['FC_active_fn'],\n",
    "                                'RNN_active_fn'     : new_parser['RNN_active_fn'],\n",
    "                                'initial_W'         : tf.contrib.layers.xavier_initializer(),\n",
    "\n",
    "                                'reg_W'             : new_parser['reg_W'],\n",
    "                                'reg_W_out'         : new_parser['reg_W_out']\n",
    "                                 }\n",
    "\n",
    "\n",
    "mb_size           = new_parser['mb_size']\n",
    "iteration         = new_parser['iteration']\n",
    "iteration_burn_in = new_parser['iteration_burn_in']\n",
    "\n",
    "keep_prob         = new_parser['keep_prob']\n",
    "lr_train          = new_parser['lr_train']\n",
    "\n",
    "alpha             = new_parser['alpha']\n",
    "beta              = new_parser['beta']\n",
    "gamma             = new_parser['gamma']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import utils_network as utils\n",
    "from tensorflow.contrib.layers import fully_connected as FC_Net\n",
    "\n",
    "_EPSILON = 1e-08\n",
    "\n",
    "def log(x):\n",
    "    return tf.log(x + _EPSILON)\n",
    "\n",
    "def div(x, y):\n",
    "    return tf.div(x, (y + _EPSILON))\n",
    "\n",
    "def get_seq_length(sequence):\n",
    "    used = tf.sign(tf.reduce_max(tf.abs(sequence), 2))\n",
    "    tmp_length = tf.reduce_sum(used, 1)\n",
    "    tmp_length = tf.cast(tmp_length, tf.int32)\n",
    "    return tmp_length\n",
    "\n",
    "# INPUT DIMENSIONS\n",
    "x_dim              = input_dims['x_dim']\n",
    "x_dim_cont         = input_dims['x_dim_cont']\n",
    "x_dim_bin          = input_dims['x_dim_bin']\n",
    "\n",
    "num_Event          = input_dims['num_Event']\n",
    "num_Category       = input_dims['num_Category']\n",
    "max_length         = input_dims['max_length']\n",
    "\n",
    "# NETWORK HYPER-PARMETERS\n",
    "h_dim1             = network_settings['h_dim_RNN']\n",
    "h_dim2             = network_settings['h_dim_FC']\n",
    "num_layers_RNN     = network_settings['num_layers_RNN']\n",
    "num_layers_ATT     = network_settings['num_layers_ATT']\n",
    "num_layers_CS      = network_settings['num_layers_CS']\n",
    "\n",
    "RNN_type           = network_settings['RNN_type']\n",
    "\n",
    "FC_active_fn       = network_settings['FC_active_fn']\n",
    "RNN_active_fn      = network_settings['RNN_active_fn']\n",
    "initial_W          = network_settings['initial_W']\n",
    "\n",
    "reg_W              = tf.contrib.layers.l1_regularizer(scale=network_settings['reg_W'])\n",
    "reg_W_out          = tf.contrib.layers.l1_regularizer(scale=network_settings['reg_W_out'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_mi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_356\\3273588953.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;31m# do same thing for missing indicator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m \u001b[0mmi_last\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m      \u001b[1;31m#current measurement\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[0mmi_last\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmi_last\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_dim_cont\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mx_dim_bin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m#remove the delta of the last measurement\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_mi' is not defined"
     ]
    }
   ],
   "source": [
    "x = data\n",
    "\n",
    "seq_length     = get_seq_length(x)\n",
    "tmp_range      = tf.expand_dims(tf.range(0, max_length, 1), axis=0)\n",
    "\n",
    "rnn_mask1 = tf.cast(tf.less_equal(tmp_range, tf.expand_dims(seq_length - 1, axis=1)), tf.float32)            \n",
    "rnn_mask2 = tf.cast(tf.equal(tmp_range, tf.expand_dims(seq_length - 1, axis=1)), tf.float32) \n",
    "\n",
    "\n",
    "### DEFINE LOOP FUNCTION FOR RAW_RNN w/ TEMPORAL ATTENTION\n",
    "def loop_fn_att(time, cell_output, cell_state, loop_state):\n",
    "\n",
    "    emit_output = cell_output \n",
    "\n",
    "    if cell_output is None:  # time == 0\n",
    "        next_cell_state = cell.zero_state(mb_size, tf.float32)\n",
    "        next_loop_state = loop_state_ta\n",
    "    else:\n",
    "        next_cell_state = cell_state\n",
    "        tmp_h = utils.create_concat_state(next_cell_state, num_layers_RNN, RNN_type)\n",
    "\n",
    "        e = utils.create_FCNet(tf.concat([tmp_h, all_last], axis=1), num_layers_ATT, h_dim2, \n",
    "                                tf.nn.tanh, 1, None, initial_W, keep_prob=keep_prob)\n",
    "        e = tf.exp(e)\n",
    "\n",
    "        next_loop_state = (loop_state[0].write(time-1, e),                # save att power (e_{j})\n",
    "                            loop_state[1].write(time-1, tmp_h))  # save all the hidden states\n",
    "\n",
    "    # elements_finished = (time >= seq_length)\n",
    "    elements_finished = (time >= max_length-1)\n",
    "\n",
    "    #this gives the break-point (no more recurrence after the max_length)\n",
    "    finished = tf.reduce_all(elements_finished)    \n",
    "    next_input = tf.cond(finished, lambda: tf.zeros([mb_size, 2*x_dim], dtype=tf.float32),  # [x_hist, mi_hist]\n",
    "                                    lambda: inputs_ta.read(time))\n",
    "\n",
    "    return (elements_finished, next_input, next_cell_state, emit_output, next_loop_state)\n",
    "\n",
    "\n",
    "\n",
    "# divide into the last x and previous x's\n",
    "x_last = tf.slice(x, [0,(max_length-1), 1], [-1,-1,-1])      #current measurement\n",
    "x_last = tf.reshape(x_last, [-1, (x_dim_cont+x_dim_bin)])    #remove the delta of the last measurement\n",
    "\n",
    "x_last = tf.reduce_sum(tf.tile(tf.expand_dims(rnn_mask2, axis=2), [1,1,x_dim]) * x, reduction_indices=1)    #sum over time since all others time stamps are 0\n",
    "x_last = tf.slice(x_last, [0,1], [-1,-1])                               #remove the delta of the last measurement\n",
    "x_hist = x * (1.-tf.tile(tf.expand_dims(rnn_mask2, axis=2), [1,1,x_dim]))                                    #since all others time stamps are 0 and measurements are 0-padded\n",
    "x_hist = tf.slice(x_hist, [0, 0, 0], [-1,(max_length-1),-1])  \n",
    "\n",
    "# do same thing for missing indicator\n",
    "mi_last = tf.slice(x_mi, [0,(max_length-1), 1], [-1,-1,-1])      #current measurement\n",
    "mi_last = tf.reshape(mi_last, [-1, (x_dim_cont+x_dim_bin)])    #remove the delta of the last measurement\n",
    "\n",
    "mi_last = tf.reduce_sum(tf.tile(tf.expand_dims(rnn_mask2, axis=2), [1,1,x_dim]) * x_mi, reduction_indices=1)    #sum over time since all others time stamps are 0\n",
    "mi_last = tf.slice(mi_last, [0,1], [-1,-1])                               #remove the delta of the last measurement\n",
    "mi_hist = x_mi * (1.-tf.tile(tf.expand_dims(rnn_mask2, axis=2), [1,1,x_dim]))                                    #since all others time stamps are 0 and measurements are 0-padded\n",
    "mi_hist = tf.slice(mi_hist, [0, 0, 0], [-1,(max_length-1),-1])  \n",
    "\n",
    "all_hist = tf.concat([x_hist, mi_hist], axis=2)\n",
    "all_last = tf.concat([x_last, mi_last], axis=1)\n",
    "\n",
    "\n",
    "#extract inputs for the temporal attention: mask (to incorporate only the measured time) and x_{M}\n",
    "seq_length     = get_seq_length(x_hist)\n",
    "rnn_mask_att   = tf.cast(tf.not_equal(tf.reduce_sum(x_hist, reduction_indices=2), 0), dtype=tf.float32)  #[mb_size, max_length-1], 1:measurements 0:no measurements\n",
    "\n",
    "\n",
    "##### SHARED SUBNETWORK: RNN w/ TEMPORAL ATTENTION\n",
    "#change the input tensor to TensorArray format with [max_length, mb_size, x_dim]\n",
    "inputs_ta = tf.TensorArray(dtype=tf.float32, size=max_length-1).unstack(_transpose_batch_time(all_hist), name = 'Shared_Input')\n",
    "\n",
    "\n",
    "#create a cell with RNN hyper-parameters (RNN types, #layers, #nodes, activation functions, keep proability)\n",
    "cell = utils.create_rnn_cell(h_dim1, num_layers_RNN, keep_prob, \n",
    "                                RNN_type, RNN_active_fn)\n",
    "\n",
    "#define the loop_state TensorArray for information from rnn time steps\n",
    "loop_state_ta = (tf.TensorArray(size=max_length-1, dtype=tf.float32),  #e values (e_{j})\n",
    "                    tf.TensorArray(size=max_length-1, dtype=tf.float32))  #hidden states (h_{j})\n",
    "\n",
    "rnn_outputs_ta, rnn_final_state, loop_state_ta = tf.nn.raw_rnn(cell, loop_fn_att)\n",
    "#rnn_outputs_ta  : TensorArray\n",
    "#rnn_final_state : Tensor\n",
    "#rnn_states_ta   : (TensorArray, TensorArray)\n",
    "\n",
    "rnn_outputs = _transpose_batch_time(rnn_outputs_ta.stack())\n",
    "# rnn_outputs =  tf.reshape(rnn_outputs, [-1, max_length-1, h_dim1])\n",
    "\n",
    "rnn_states  = _transpose_batch_time(loop_state_ta[1].stack())\n",
    "\n",
    "att_weight  = _transpose_batch_time(loop_state_ta[0].stack()) #e_{j}\n",
    "att_weight  = tf.reshape(att_weight, [-1, max_length-1]) * rnn_mask_att # masking to set 0 for the unmeasured e_{j}\n",
    "\n",
    "#get a_{j} = e_{j}/sum_{l=1}^{M-1}e_{l}\n",
    "att_weight  = div(att_weight,(tf.reduce_sum(att_weight, axis=1, keepdims=True) + _EPSILON)) #softmax (tf.exp is done, previously)\n",
    "\n",
    "# 1) expand att_weight to hidden state dimension, 2) c = \\sum_{j=1}^{M} a_{j} x h_{j}\n",
    "context_vec = tf.reduce_sum(tf.tile(tf.reshape(att_weight, [-1, max_length-1, 1]), [1, 1, num_layers_RNN*h_dim1]) * rnn_states, axis=1)\n",
    "\n",
    "\n",
    "z_mean      = FC_Net(rnn_outputs, x_dim, activation_fn=None, weights_initializer=initial_W, scope=\"RNN_out_mean1\")\n",
    "z_std       = tf.exp(FC_Net(rnn_outputs, x_dim, activation_fn=None, weights_initializer=initial_W, scope=\"RNN_out_std1\"))\n",
    "\n",
    "epsilon          = tf.random_normal([mb_size, max_length-1, x_dim], mean=0.0, stddev=1.0, dtype=tf.float32)\n",
    "z           = z_mean + z_std * epsilon\n",
    "\n",
    "\n",
    "##### CS-SPECIFIC SUBNETWORK w/ FCNETS \n",
    "inputs = tf.concat([x_last, context_vec], axis=1)\n",
    "\n",
    "\n",
    "#1 layer for combining inputs\n",
    "h = FC_Net(inputs, h_dim2, activation_fn=FC_active_fn, weights_initializer=initial_W, scope=\"Layer1\")\n",
    "h = tf.nn.dropout(h, keep_prob=keep_prob)\n",
    "\n",
    "# (num_layers_CS-1) layers for cause-specific (num_Event subNets)\n",
    "out = []\n",
    "for _ in range(num_Event):\n",
    "    cs_out = utils.create_FCNet(h, (num_layers_CS), h_dim2, FC_active_fn, h_dim2, FC_active_fn, initial_W, reg_W, keep_prob)\n",
    "    out.append(cs_out)\n",
    "out = tf.stack(out, axis=1) # stack referenced on subject\n",
    "out = tf.reshape(out, [-1, num_Event*h_dim2])\n",
    "out = tf.nn.dropout(out, keep_prob=keep_prob)\n",
    "\n",
    "out = FC_Net(out, num_Event * num_Category, activation_fn=tf.nn.softmax, \n",
    "                weights_initializer=initial_W, weights_regularizer=reg_W_out, scope=\"Output\")\n",
    "out = tf.reshape(out, [-1, num_Event, num_Category])\n",
    "\n",
    "\n",
    "##### GET LOSS FUNCTIONS\n",
    "loss_Log_Likelihood()      #get loss1: Log-Likelihood loss\n",
    "loss_Ranking()             #get loss2: Ranking loss\n",
    "loss_RNN_Prediction()      #get loss3: RNN prediction loss\n",
    "\n",
    "LOSS_TOTAL     = a*LOSS_1 + b*LOSS_2 + c*LOSS_3 + tf.losses.get_regularization_loss()\n",
    "LOSS_BURNIN    = LOSS_3 + tf.losses.get_regularization_loss()\n",
    "\n",
    "solver         = tf.train.AdamOptimizer(learning_rate=lr_rate).minimize(LOSS_TOTAL)\n",
    "solver_burn_in = tf.train.AdamOptimizer(learning_rate=lr_rate).minimize(LOSS_BURNIN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=32, shape=(32, 1, 15), dtype=float32, numpy=\n",
       "array([[[-1.21184146e+00,  4.48889762e-01, -7.37403184e-02,\n",
       "          7.54432082e-01,  1.48847151e+00, -1.52995682e+00,\n",
       "         -6.03821278e-01,  5.47428668e-01, -8.55400443e-01,\n",
       "          1.44296741e+00, -6.51406288e-01, -3.30137253e-01,\n",
       "         -1.14750016e+00, -2.40512347e+00, -3.09611768e-01]],\n",
       "\n",
       "       [[ 1.14851883e-02, -1.92178220e-01, -2.14976120e+00,\n",
       "         -5.76461256e-01, -1.12946346e-01,  1.36483836e+00,\n",
       "          9.55794930e-01, -1.29790676e+00,  1.19078565e+00,\n",
       "          1.66978955e+00,  5.24244070e-01,  5.06962612e-02,\n",
       "         -1.28597736e-01,  9.25031304e-02, -6.54789388e-01]],\n",
       "\n",
       "       [[ 1.40942708e-01,  1.30323052e+00,  3.42019469e-01,\n",
       "          4.77353007e-01, -4.16334450e-01,  7.89854348e-01,\n",
       "          8.25113595e-01, -5.37863255e-01,  1.52390099e+00,\n",
       "          2.24795505e-01,  2.97209203e-01, -3.64836961e-01,\n",
       "          3.32593441e-01, -8.87461960e-01,  1.05487764e+00]],\n",
       "\n",
       "       [[ 5.10776818e-01,  1.30140638e+00,  5.28486907e-01,\n",
       "          4.51047331e-01, -1.03694856e+00,  9.16078746e-01,\n",
       "         -7.22177446e-01,  7.78226554e-01, -2.17435551e+00,\n",
       "         -1.87981781e-02, -1.07288694e+00,  1.11909902e+00,\n",
       "         -1.57031626e-01,  2.85916042e+00,  4.53482836e-01]],\n",
       "\n",
       "       [[ 1.06418991e+00,  9.94191110e-01, -4.63683009e-01,\n",
       "         -7.90388882e-02,  1.39713943e+00,  5.49754739e-01,\n",
       "          7.82049179e-01,  6.29380286e-01, -1.46897733e+00,\n",
       "         -4.67782915e-01, -1.00021100e+00, -2.68690348e-01,\n",
       "         -1.27170312e+00, -1.84758261e-01, -9.69199896e-01]],\n",
       "\n",
       "       [[-1.06956255e+00,  5.23521423e-01,  5.27443171e-01,\n",
       "         -1.11645555e+00, -5.07047713e-01, -1.48796666e+00,\n",
       "         -8.25127304e-01, -9.73988295e-01, -1.57614088e+00,\n",
       "         -3.21465760e-01, -4.08541746e-02, -3.13810706e-01,\n",
       "         -1.34360158e+00,  4.23923045e-01,  4.48784918e-01]],\n",
       "\n",
       "       [[ 5.09686530e-01,  6.58582598e-02,  1.72700870e+00,\n",
       "         -1.33592355e+00,  7.80862749e-01,  2.31125760e+00,\n",
       "         -1.47178614e+00,  3.86759102e-01, -3.71589422e-01,\n",
       "         -3.96235287e-01, -9.03612673e-01,  5.52594662e-01,\n",
       "          2.35673213e+00,  7.12612867e-01, -2.78505385e-01]],\n",
       "\n",
       "       [[ 1.60100192e-01, -5.70905387e-01, -1.21335603e-01,\n",
       "         -6.29401863e-01, -2.04233670e+00, -1.88516819e+00,\n",
       "         -3.75291765e-01,  5.64858317e-01,  1.69493210e+00,\n",
       "         -1.96842313e+00,  1.13630176e+00, -8.80435824e-01,\n",
       "         -3.76607478e-01,  4.65680799e-03, -2.39925608e-01]],\n",
       "\n",
       "       [[ 5.55650413e-01,  8.44100952e-01,  8.54321539e-01,\n",
       "         -1.76651824e+00,  1.31453514e+00, -4.81534094e-01,\n",
       "         -1.98194385e+00,  4.49104868e-02, -9.19712007e-01,\n",
       "          1.01604486e+00, -9.23647523e-01, -6.78135514e-01,\n",
       "         -8.23599875e-01,  6.76647544e-01, -1.45086959e-01]],\n",
       "\n",
       "       [[ 8.08006644e-01, -5.31395674e-01,  9.90252256e-01,\n",
       "         -1.44950002e-01,  3.56351107e-01, -2.99395919e-01,\n",
       "         -4.77996767e-01,  1.09319615e+00,  4.44854796e-01,\n",
       "         -1.28567004e+00,  5.67733012e-02, -1.14042854e+00,\n",
       "          6.89221919e-01,  1.99037462e-01,  9.62668657e-01]],\n",
       "\n",
       "       [[-9.26193237e-01,  1.20129561e+00,  4.92593020e-01,\n",
       "          1.07075691e+00, -2.34160408e-01, -8.65684927e-01,\n",
       "          9.60819364e-01,  8.76470745e-01, -5.05657136e-01,\n",
       "          1.29749739e+00, -6.41006291e-01, -2.14622617e+00,\n",
       "          4.07891840e-01, -1.86388171e+00,  5.92951953e-01]],\n",
       "\n",
       "       [[-3.32828492e-01, -8.25496256e-01,  1.31975210e+00,\n",
       "          1.07098806e+00,  8.04471433e-01,  3.16709518e+00,\n",
       "         -1.19508159e+00, -4.97518003e-01, -6.50062621e-01,\n",
       "          3.59100923e-02, -9.23828065e-01,  7.60563254e-01,\n",
       "          4.21290755e-01, -7.40391135e-01, -3.32673073e-01]],\n",
       "\n",
       "       [[-1.14694703e+00, -2.09882593e+00,  1.49200070e+00,\n",
       "          1.08188117e+00, -1.05509675e+00, -1.22523117e+00,\n",
       "          7.47757316e-01, -2.26604253e-01, -1.25412643e+00,\n",
       "          1.44646275e+00,  2.10539117e-01,  8.46294239e-02,\n",
       "         -2.67802685e-01,  1.09317712e-01,  8.19011986e-01]],\n",
       "\n",
       "       [[-1.23004951e-01, -1.37108481e+00,  8.85891676e-01,\n",
       "         -1.26171470e+00,  4.56441134e-01, -1.45746517e+00,\n",
       "          4.68212813e-01,  2.86518604e-01, -5.27130902e-01,\n",
       "          1.29370642e+00, -4.04130012e-01, -9.99742925e-01,\n",
       "         -1.24169457e+00,  1.07757866e+00,  1.33685422e+00]],\n",
       "\n",
       "       [[ 4.59092081e-01,  9.04930308e-02,  5.39912939e-01,\n",
       "         -4.28375155e-01,  1.11344850e+00, -3.42850387e-01,\n",
       "          3.41721803e-01, -8.36296499e-01,  2.14360297e-01,\n",
       "         -1.23441555e-01, -2.14324798e-02,  1.36348796e+00,\n",
       "          7.37983704e-01,  9.36724067e-01,  7.70934880e-01]],\n",
       "\n",
       "       [[-7.22423077e-01, -6.54568970e-01,  3.29469353e-01,\n",
       "         -1.61123738e-01, -1.05869412e+00,  3.72874320e-01,\n",
       "         -6.78676903e-01, -9.12075192e-02,  2.97856867e-01,\n",
       "         -1.03444934e+00,  6.92525983e-01, -7.43066907e-01,\n",
       "          3.37862447e-02, -6.02609932e-01,  9.19242680e-01]],\n",
       "\n",
       "       [[ 1.68674028e+00,  1.86827695e+00,  1.50864959e+00,\n",
       "          1.34734964e+00,  1.18468308e+00,  4.82221067e-01,\n",
       "          1.20231473e+00, -9.13411379e-01,  3.56991529e-01,\n",
       "          2.74129033e-01,  1.01320446e+00, -1.59513921e-01,\n",
       "          4.71002936e-01, -1.88573480e+00,  9.44275677e-01]],\n",
       "\n",
       "       [[-1.24267602e+00, -4.61306274e-01, -1.56781209e+00,\n",
       "          5.86773515e-01,  3.07644427e-01,  2.95502782e-01,\n",
       "         -7.19444335e-01, -6.05422594e-02, -4.75475103e-01,\n",
       "          8.33081543e-01, -1.37053758e-01, -3.62711221e-01,\n",
       "          1.68951488e+00, -7.45196521e-01,  2.70736068e-01]],\n",
       "\n",
       "       [[-6.60474837e-01, -6.98953092e-01,  1.17535189e-01,\n",
       "         -7.23696172e-01,  7.49088645e-01, -8.48553404e-02,\n",
       "          1.34783417e-01, -1.95292294e-01,  9.15709138e-01,\n",
       "          9.26717520e-01,  4.25018042e-01, -3.58269550e-02,\n",
       "          1.47712797e-01,  8.99884164e-01,  1.44755042e+00]],\n",
       "\n",
       "       [[-6.79241538e-01,  2.20874810e+00, -4.56180274e-01,\n",
       "         -1.08458674e+00,  5.90889037e-01,  2.67990136e+00,\n",
       "         -1.64562654e+00, -4.76042747e-01, -1.03455555e+00,\n",
       "          1.68587521e-01, -1.93277337e-02, -1.12650239e+00,\n",
       "         -2.61709362e-01, -2.82399476e-01,  6.66497350e-02]],\n",
       "\n",
       "       [[ 2.37390086e-01, -6.57539427e-01, -1.17308474e+00,\n",
       "         -1.51647818e+00,  1.04209530e+00,  3.17081720e-01,\n",
       "          3.88946623e-01,  7.91385889e-01, -4.41076070e-01,\n",
       "         -3.26830119e-01,  5.72152615e-01,  1.00543547e+00,\n",
       "         -2.68823504e-01,  1.95460689e+00, -4.37406731e+00]],\n",
       "\n",
       "       [[-7.42291331e-01, -4.82952207e-01, -5.09955287e-01,\n",
       "         -1.91104996e+00,  1.22761345e+00, -1.54841855e-01,\n",
       "         -1.22354913e+00, -8.58670473e-01,  2.77642488e+00,\n",
       "         -5.05224586e-01,  1.98454529e-01, -1.16854608e+00,\n",
       "         -2.72926331e+00,  1.37988403e-01, -8.51176560e-01]],\n",
       "\n",
       "       [[ 5.10342538e-01, -1.08933844e-01, -8.23984981e-01,\n",
       "         -9.27572489e-01, -1.29308045e-01, -3.33026707e-01,\n",
       "          5.63970149e-01, -5.73548973e-01,  1.12606072e+00,\n",
       "         -7.19060719e-01,  7.08167315e-01,  1.20047390e+00,\n",
       "         -2.08081746e+00,  2.35162988e-01,  4.02090363e-02]],\n",
       "\n",
       "       [[-2.91104615e-01, -8.00709963e-01, -1.41073167e+00,\n",
       "          3.88678759e-01,  3.36205870e-01,  9.83834743e-01,\n",
       "         -1.46343246e-01, -6.07745826e-01,  1.26479626e+00,\n",
       "         -5.32993495e-01, -8.88591781e-02, -2.01779589e-01,\n",
       "          1.36871076e+00,  2.67145187e-01, -6.84658706e-01]],\n",
       "\n",
       "       [[ 1.62568584e-01, -4.65000451e-01, -6.90939248e-01,\n",
       "         -4.58551973e-01, -5.08399010e-01, -3.72972697e-01,\n",
       "         -7.82226682e-01, -9.55448300e-02, -1.71640253e+00,\n",
       "         -6.51041567e-01,  8.11420202e-01,  8.72884929e-01,\n",
       "          4.48997080e-01, -8.81783187e-01, -1.48546183e+00]],\n",
       "\n",
       "       [[-9.82951522e-01, -9.13689099e-03,  2.44552672e-01,\n",
       "          6.20755374e-01,  1.35420036e+00,  1.37181073e-01,\n",
       "          1.39127362e+00, -2.01659757e-04,  7.10019290e-01,\n",
       "          2.56783515e-01,  1.86719403e-01,  3.49715829e-01,\n",
       "         -1.95812657e-01, -5.29353857e-01,  1.42878270e+00]],\n",
       "\n",
       "       [[-8.03088725e-01,  1.91348065e-02, -3.36852193e-01,\n",
       "         -3.50220144e-01, -2.22832575e-01,  1.28781760e+00,\n",
       "          7.61487365e-01, -7.95116425e-01, -2.10990405e+00,\n",
       "          8.14027369e-01, -1.74090588e+00, -4.13466543e-01,\n",
       "          1.01018257e-01, -9.49121594e-01, -4.93482322e-01]],\n",
       "\n",
       "       [[ 9.27848592e-02,  3.97062838e-01,  1.04682481e+00,\n",
       "          7.15317801e-02, -5.72584808e-01, -8.11570957e-02,\n",
       "         -7.00722039e-01,  8.14010441e-01, -4.08984423e-01,\n",
       "          2.04922867e+00,  7.54160434e-02, -1.32145202e+00,\n",
       "         -4.80287701e-01, -8.24644506e-01, -2.51005626e+00]],\n",
       "\n",
       "       [[-7.54144341e-02,  8.93986225e-01, -1.12375295e+00,\n",
       "          1.03396140e-02,  1.39378488e+00,  9.64841366e-01,\n",
       "         -1.47833002e+00, -1.44754660e+00, -1.78419888e+00,\n",
       "          5.19755542e-01,  7.99837470e-01,  7.91459307e-02,\n",
       "         -9.78230163e-02,  2.84441799e-01, -1.37659478e+00]],\n",
       "\n",
       "       [[-1.08109069e+00, -1.41350865e+00, -1.58813989e+00,\n",
       "         -2.04884801e-02, -4.24085528e-01,  4.74813372e-01,\n",
       "         -1.50027737e-01,  4.41942401e-02,  8.96538854e-01,\n",
       "         -3.98482233e-01, -1.51308760e-01,  9.61857557e-01,\n",
       "         -2.09513688e+00, -1.78882146e+00, -1.65328336e+00]],\n",
       "\n",
       "       [[ 9.35868204e-01, -3.12345792e-02,  3.05502176e-01,\n",
       "          9.70539004e-02, -7.06901014e-01,  1.63523877e+00,\n",
       "         -6.86200261e-01, -2.67748594e-01,  3.56399491e-02,\n",
       "         -4.40020800e-01, -1.89741778e+00,  8.64251435e-01,\n",
       "         -1.73518494e-01,  2.14632797e+00, -1.82001412e+00]],\n",
       "\n",
       "       [[ 5.76869547e-01, -7.52586544e-01, -1.09645939e+00,\n",
       "         -1.30870092e+00,  2.39291978e+00,  9.71288204e-01,\n",
       "         -2.10723802e-01,  2.33014536e+00, -8.29996765e-01,\n",
       "          1.24554420e+00, -1.35648346e+00,  9.12266016e-01,\n",
       "          1.62389863e+00,  2.60528713e-01,  3.94892007e-01]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x = tf.random.normal([32,16,16], 0, 1, tf.float32, seed=1)\n",
    "# x.shape[1]\n",
    "# max_length = x.shape[1]\n",
    "# tf.slice(x, [0,(max_length-1), 1], [-1,-1,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ca1e5c092f7dd49e29e82c38e1d556147bc3e03db06c6b27903751c18dc751f9"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
